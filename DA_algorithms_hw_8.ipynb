{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DA_algorithms_hw_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhdMf2dztKf+FBDUfPZaTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedokormysh/GB_DA_algorithms/blob/lesson8/DA_algorithms_hw_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vyDZoDkhD3qA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1.\n",
        "\n",
        "Обучить любую модель классификации на датасете IRIS до применения PCA и после него. Сравнить качество классификации по отложенной выборке."
      ],
      "metadata": {
        "id": "ScTn-3QF1-0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA с занятия."
      ],
      "metadata": {
        "id": "L3Qr7PTVDaEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y, y_pred):\n",
        "  return np.sum(y == y_pred) / len(y)\n",
        "\n",
        "def e_metrics(x1, x2):\n",
        "    distance = np.sum(np.square(x1 - x2))\n",
        "    return np.sqrt(distance)\n",
        "\n",
        "def standart_scale(X):\n",
        "  X_ = X.astype(float)\n",
        "  return X - X.mean(axis=0) / np.std(X_, axis=0) "
      ],
      "metadata": {
        "id": "UBpmYG_93Dbo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knn с прошлого занятия\n",
        "def knn(x_train, y_train, x_test, k, weights=False, q = 0.5):\n",
        "    \n",
        "    answers = []\n",
        "    for x in x_test:\n",
        "        test_distances = [] # обнуляем список вычесленных расстояний.\n",
        "\n",
        "\n",
        "        #print(len(answers))    \n",
        "        for i in range(len(x_train)):\n",
        "            \n",
        "            # расчет расстояния от классифицируемого объекта до\n",
        "            # объекта обучающей выборки\n",
        "            distance = e_metrics(x, x_train[i])\n",
        "                        \n",
        "            # Записываем в список значение расстояния и ответа на объекте обучающей выборки\n",
        "            test_distances.append((distance, y_train[i]))\n",
        "        \n",
        "        # создаем словарь со всеми возможными классами\n",
        "        classes = {class_item: 0 for class_item in set(y_train)}\n",
        "\n",
        "        # Сортируем список и среди первых k элементов подсчитаем частоту появления разных классов\n",
        "        for d in sorted(test_distances)[0:k]:\n",
        "          if weights == True:\n",
        "            weight = q ** d[0]\n",
        "            classes[d[1]] += weight\n",
        "          else:\n",
        "            classes[d[1]] += 1\n",
        "            \n",
        "        # Записываем в список ответов наиболее часто встречающийся класс\n",
        "        answers.append(sorted(classes, key=classes.get)[-1])\n",
        "    return answers"
      ],
      "metadata": {
        "id": "KRf_3hMJ250v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# соберём pca\n",
        "def pca(X, component=1, visual=False):\n",
        "  # Найдем собственные векторы и собственные значения\n",
        "  covariance_matrix = X.T.dot(X)\n",
        "  eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
        "  \n",
        "  # сформируем список кортежей (собственное значение, собственный вектор)\n",
        "  eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
        "\n",
        "  # и отсортируем список по убыванию собственных значений\n",
        "  eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "  eig_sum = sum(eig_values)\n",
        "  var_exp = [(i / eig_sum) * 100 for i in sorted(eig_values, reverse=True)]\n",
        "  cum_var_exp = np.cumsum(var_exp)\n",
        "  \n",
        "  # Сформируем вектор весов из собственных векторов\n",
        "  W = np.hstack([eig_pairs[i][1].reshape(len(eig_pairs[i][1]),1) for i in range(component)])\n",
        "\n",
        "  # Сформируем новую матрицу \"объекты-признаки\"\n",
        "  Z = X.dot(W)\n",
        "\n",
        "  if visual:\n",
        "    print('Собственные значения в порядке убывания:')\n",
        "    for i in eig_pairs:\n",
        "      print(i)\n",
        "\n",
        "    print('-'*50) \n",
        "\n",
        "    print(f'Доля дисперсии, описываемая каждой из компонент \\n{var_exp}')\n",
        "\n",
        "    # а теперя оценим кумулятивную (то есть накапливаемую) дисперсию при учитывании каждой из компонент\n",
        "    print(f'Кумулятивная доля дисперсии по компонентам \\n{cum_var_exp}')\n",
        "\n",
        "    print('-'*50)  \n",
        "    print(f'Матрица весов W:\\n', W)\n",
        "\n",
        "  return Z"
      ],
      "metadata": {
        "id": "E4C3mIhH36Ef"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузим игрушечный датасет из sklearn\n",
        "iris = datasets.load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target\n",
        "X_iris.shape, y_iris.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqmR2LnT16iY",
        "outputId": "0c2f2777-6c62-4482-997b-768ed55c0a6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# стандартизируем признаки\n",
        "\n",
        "X_iris_st = standart_scale(X_iris)"
      ],
      "metadata": {
        "id": "lIRFegEsAEBK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_iris, X_test_iris, Y_train_iris, Y_test_iris = train_test_split(X_iris_st, y_iris,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=24,\n",
        "                                                    stratify=y_iris)\n",
        "X_train_iris.shape, X_test_iris.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYfYSA5mAGlc",
        "outputId": "172f599a-fa59-4561-87ba-84106a1de21a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((105, 4), (45, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn(X_train_iris, Y_train_iris, X_test_iris, 5, weights=True)"
      ],
      "metadata": {
        "id": "UXWwK_K1ATca"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Применим алгоритм уменьшения размерности PCA\n",
        "\n",
        "X_pca = pca(X_iris_st, component=2)\n",
        "# X_pca[:10]"
      ],
      "metadata": {
        "id": "MgiNbpvODtgM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Снова разобьем данные\n",
        "\n",
        "X_train_iris_pca, X_test_iris_pca, Y_train_iris_pca, Y_test_iris_pca = train_test_split(X_pca, y_iris,\n",
        "                                                            test_size=0.3,\n",
        "                                                            random_state=24,\n",
        "                                                            stratify=y_iris)\n",
        "X_train_iris_pca.shape, X_test_iris_pca.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jyiT2QAD0C3",
        "outputId": "c9977bac-37c0-482a-fbff-053e042688de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((105, 2), (45, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучим модель KNN после применения PCA\n",
        "y_pred_pca = knn(X_train_iris_pca, Y_train_iris_pca, X_test_iris_pca, 5, weights=True)"
      ],
      "metadata": {
        "id": "VuwwgYt8EaEK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Модель KNN до применения PCA, accuracy: {accuracy(Y_test_iris, y_pred):.4f}', \n",
        "      f'Модель KNN после применения PCA, accuracy: {accuracy(Y_test_iris_pca, y_pred_pca):.4f}', sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkTMi616Eb_m",
        "outputId": "7d5c66ec-6314-4bf6-8265-97fc34d36ec3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель KNN до применения PCA, accuracy: 0.9556\n",
            "Модель KNN после применения PCA, accuracy: 0.9111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA встроенный в sklearn"
      ],
      "metadata": {
        "id": "3lYhxdwnDi0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "P20lRMgFC0wB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "import seaborn as sns\n",
        "\n",
        "digits = load_digits()\n",
        "X_load_digits = digits.data\n",
        "y_load_digits = digits.target\n",
        "X_load_digits.shape, y_load_digits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAgbXbIWC-pI",
        "outputId": "4bf1cd37-d451-416c-b597-b273ccc3bfee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1797, 64), (1797,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_load_digits, X_test_load_digits, Y_train_load_digits, Y_test_load_digits = train_test_split(X_load_digits, y_load_digits,\n",
        "                                                            test_size=0.3,\n",
        "                                                            random_state=24,\n",
        "                                                            stratify=y_load_digits)\n",
        "X_train_load_digits.shape, X_test_load_digits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxBB-0LdL4yv",
        "outputId": "05e5a405-ff6d-4faa-a38a-4feda5a6fe56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1257, 64), (540, 64))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls = LogisticRegression(solver='liblinear').fit(X_train_load_digits, Y_train_load_digits)\n",
        "\n",
        "\n",
        "tPCA = PCA(n_components=10)\n",
        "tPCA.fit(X_train_load_digits)\n",
        "X_test_pca_load_digits = tPCA.transform(X_test_load_digits)\n",
        "\n",
        "cls_pca = LogisticRegression(solver='liblinear').fit(tPCA.transform(X_train_load_digits), Y_train_load_digits)\n",
        "\n",
        "y_p_prob = cls.predict_proba(X_test_load_digits)#[:,1]\n",
        "y_p_pca_prob = cls_pca.predict_proba(X_test_pca_load_digits)#[:,1]\n",
        "\n",
        "y_p = cls.predict(X_test_load_digits)#[:,1]\n",
        "y_p_pca = cls_pca.predict(X_test_pca_load_digits)#[:,1]"
      ],
      "metadata": {
        "id": "JhkcW11bLumy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay, roc_curve, roc_auc_score, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xB_78B_9SyVK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Модель LogisticRegression до применения PCA, accuracy: {accuracy(Y_test_load_digits, y_p)}', \n",
        "      f'Модель LogisticRegression после применения PCA, accuracy: {accuracy(Y_test_load_digits, y_p_pca)}', sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1zlY1TpUtTq",
        "outputId": "ceb1ae7d-3033-43f9-ae95-e042f2c4590e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель LogisticRegression до применения PCA, accuracy: 0.9555555555555556\n",
            "Модель LogisticRegression после применения PCA, accuracy: 0.9222222222222223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "При применении PCA у меня в обоих случаях (разные датасеты и разные модели) выше точность уменьшилась относительно использования применения моделей без понижения размерности."
      ],
      "metadata": {
        "id": "Scp2YS0IhJUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'linear roc_auc_score = {roc_auc_score(Y_test_load_digits, y_p_prob, average=\"weighted\", multi_class=\"ovr\")}')\n",
        "print(f'linear+pca roc_auc_score = {roc_auc_score(Y_test_load_digits, y_p_pca_prob, average=\"weighted\", multi_class=\"ovr\")}')"
      ],
      "metadata": {
        "id": "SNSEXB_hn7qB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69295121-c250-4c24-f6f3-517a622d7b59"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear roc_auc_score = 0.9980106704641046\n",
            "linear+pca roc_auc_score = 0.9930071278977135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2.\n",
        "\n",
        "Написать свою реализацию метода главных компонент с помощью сингулярного разложения с использованием функции numpy.linalg.svd()"
      ],
      "metadata": {
        "id": "Dtrmj8JKF-2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svd(X, components=3):\n",
        "  U, s, W = np.linalg.svd(X)\n",
        "\n",
        "  D = np.zeros_like(X, dtype=float)\n",
        "  D[np.diag_indices(min(X.shape))] = s\n",
        "\n",
        "  D = D[:, :components]\n",
        "  W = W[:components, :]\n",
        "\n",
        "  # исходная матрица\n",
        "  X_ = U.dot(D.dot(W))\n",
        "    \n",
        "  print(f'Проверка разложения. Восстановление исходной матрицы.:\\n {X_}\\n')\n",
        "  print(f'Матрица весов\\n {W}\\n')\n",
        "  \n",
        "  Z = U @ D\n",
        "  print(f'Трансформированная матрица:\\n {Z}\\n')\n",
        "  # return Z"
      ],
      "metadata": {
        "id": "LORO-3PjGDKG"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[1, 2, 0], [0, 0, 5], [3, -4, 2], [1, 6, 5], [0, 1, 0]])\n",
        "\n",
        "svd(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdRB966vM9Xh",
        "outputId": "f138c05a-54bd-4171-8ac1-56b3ec3d8cab"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Проверка разложения. Восстановление исходной матрицы.:\n",
            " [[ 1.00000000e+00  2.00000000e+00  1.33720949e-15]\n",
            " [ 1.33806959e-16 -3.25169545e-15  5.00000000e+00]\n",
            " [ 3.00000000e+00 -4.00000000e+00  2.00000000e+00]\n",
            " [ 1.00000000e+00  6.00000000e+00  5.00000000e+00]\n",
            " [-3.55459915e-17  1.00000000e+00 -4.93664785e-18]]\n",
            "\n",
            "Матрица весов\n",
            " [[ 0.07116451  0.71702467  0.69340553]\n",
            " [-0.36737824  0.66514082 -0.65009301]\n",
            " [-0.92734505 -0.20847855  0.31075368]]\n",
            "\n",
            "Трансформированная матрица:\n",
            " [[ 1.50521386  0.9629034  -1.34430215]\n",
            " [ 3.46702765 -3.25046504  1.5537684 ]\n",
            " [-1.26779411 -5.06288401 -1.32661359]\n",
            " [ 7.8403402   0.37300164 -0.62444796]\n",
            " [ 0.71702467  0.66514082 -0.20847855]]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}